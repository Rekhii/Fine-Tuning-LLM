{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42vn6ETu62IO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVitzdMH6zUO"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "\n",
    "import nbformat as nbf\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "# ✅ Update path for your new notebook\n",
    "in_path = Path(\"/content/drive/MyDrive/Colab Notebooks/BERT_base_Supervised_Fine_Tuning.ipynb\")\n",
    "out_path = in_path.with_name(in_path.stem + \"_clean.ipynb\")\n",
    "\n",
    "# Read notebook\n",
    "with open(in_path, encoding=\"utf-8\") as f:\n",
    "    nb = nbf.read(f, as_version=4)\n",
    "\n",
    "# 1) Drop broken widgets metadata\n",
    "if \"widgets\" in nb.metadata:\n",
    "    del nb.metadata[\"widgets\"]\n",
    "\n",
    "# 2) Strip widget-view outputs (cause GitHub render errors)\n",
    "for cell in nb.cells:\n",
    "    if cell.get(\"outputs\"):\n",
    "        new_outputs = []\n",
    "        for o in cell[\"outputs\"]:\n",
    "            d = o.get(\"data\", {})\n",
    "            if isinstance(d, dict) and \"application/vnd.jupyter.widget-view+json\" in d:\n",
    "                continue\n",
    "            new_outputs.append(o)\n",
    "        cell[\"outputs\"] = new_outputs\n",
    "    cell.get(\"metadata\", {}).pop(\"execution\", None)  # optional cleanup\n",
    "\n",
    "# Save cleaned copy\n",
    "nbf.write(nb, out_path)\n",
    "print(\"✅ Cleaned notebook saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22560,
     "status": "ok",
     "timestamp": 1756368156507,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "Tz4K_eHNqv9w",
    "outputId": "b52a228b-8291-40c8-b769-6e529a2e3e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.8.9-py3-none-any.whl.metadata (52 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
      "Collecting trl\n",
      "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting unsloth_zoo>=2025.8.8 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.8.8-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.8.0+cu126)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting datasets<4.0.0,>=3.4.1 (from unsloth)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.10.1)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.17.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.34.4)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.35.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.23.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n",
      "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.8->unsloth) (0.10.0)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.8->unsloth) (11.3.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.8.8->unsloth)\n",
      "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (13.9.4)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.15)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\n",
      "Downloading unsloth-2025.8.9-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.8.8-py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.8/184.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.28-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shtab, msgspec, tyro, xformers, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "Successfully installed bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 datasets-3.6.0 msgspec-0.19.0 shtab-1.7.2 trl-0.21.0 tyro-0.9.28 unsloth-2025.8.9 unsloth_zoo-2025.8.8 xformers-0.0.32.post2\n"
     ]
    }
   ],
   "source": [
    "pip install unsloth transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb8fkLFFrOxE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth.chat_templates import get_chat_template, standardize_sharegpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306,
     "referenced_widgets": [
      "d26202974cc84e5ea591c8c6b7aa46ae",
      "e0e93f90c09a4d139ae9b4a0d57b3448",
      "22d04e5acb4c4494a5083fa3b4d27204",
      "5b924ac9653b45eabe7cf7eae3022b02",
      "10216abafff74da6922bc3aad7a15940",
      "ea7b9a955fb2448ebea6e6b3bdead186",
      "e845c5b503a347328f632b19eed077db",
      "752ae10747104ecb9f385ea990b87269",
      "76cc4846803a414d8a2690800e31c884",
      "8c7c31538a19450ca82a6e83ce8ca6e5",
      "592bace59c644db599e975bc1defb73a",
      "c801bf1763fc4b9bbdfd0e7e522490e9",
      "78e726b8c9e3452f9190e85876d504da",
      "ee59ab481ade4320ad4c65bd492a5491",
      "89cfe1f429574ee5bcde955163a20689",
      "fa9a89621a1b4f3bbcd24b9494ba5abd",
      "ac38f63ff68543ee8f035ac4aa3c75b0",
      "550d8b8b1a7843d28e4ea04884993eae",
      "d92a4faf831441759d7fa5aaa280f7df",
      "00f19984cbda4777a76d0ce8525894b7",
      "00dcda882d9748799bbe1c8e02b7344d",
      "01f4f5b1610b451da96078cd2c114313",
      "393801fb8bcb477e9a895fde3e5e35f1",
      "61ef29cd3b13434a98720659f70067dc",
      "c187e334db784092b75cc8d36c8def02",
      "266a9d214cfe4b1aa5baf99534331444",
      "8214040f48a34def98f1ceda405ab6cf",
      "3054c34f8b4049bebb1584590e42b05b",
      "d25dcb2f695649068faa83ab812dc0e7",
      "03705139455744aeacea63a092e7171b",
      "b1877aad17ef4f92acd89077041851a4",
      "590468d62e024da78ba76a6cb2c6c728",
      "f858010955df411fa43d6c28b27f9051",
      "8f1c0c22758c4584b2b104f6fd7f47a8",
      "604905f377524db8b3b1dd1e4f74ec24",
      "d3e1bda8283a4fbc8bc9ce3fa20cb784",
      "300031453183404b81db053f16a57fb1",
      "062540410d674aefa474a05a705b16c0",
      "a5f47de1c56d4dcab2a2ba8e66c6b4b8",
      "6ce002792ae343aaad57d4e17ea1d19e",
      "0b60187ba5a44c028e9f155c678fc25e",
      "c98912d3a1234032a7a4cfb928d1f8d0",
      "8fa3442f41264a4599908bebb8ca63df",
      "e0c1a249b9dd4abb83214f287afacbdf",
      "94c82a301394404dab6e311c049dc4f5",
      "11946d998ffb4290bd86c511109ef86e",
      "b0adb98729fe4b3187dfad72683e0ae3",
      "86043ad6858841c7b724187137e2d165",
      "35ae8e4370e847cc80585da695cbccb1",
      "a6f81ed7d10740c19ac0cfa0d891a009",
      "47a567da1bb2403c90260e24f30d435d",
      "32c3ec737efa4069b3c2905e6e7a9496",
      "2de7a3354168435396515bcc6fc8666c",
      "cfbb68d4226f451dac6d530d8d4cdaa3",
      "57b6aed662684fc69db0b206f7d2fa57"
     ]
    },
    "executionInfo": {
     "elapsed": 29221,
     "status": "ok",
     "timestamp": 1756368514723,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "9V3zZjoGsJka",
    "outputId": "9970428e-06a4-484f-ac53-f81fcab22806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name =  \"unsloth/Llama-3.2-1B-Instruct\",\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12754,
     "status": "ok",
     "timestamp": 1756368795517,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "_jqoFerlt-1z",
    "outputId": "c069fc3e-23a1-42e5-a06e-f7bb859e0747"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.9 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model, r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AC9eEXbkvMUB"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(tokenizer,chat_template= \"llama-3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141,
     "referenced_widgets": [
      "4d76e7bd0ed14d1689aee359937bc790",
      "4a0fa1ba627141e5b6e4d5ace4d20e1a",
      "9f0a1f5e6c4f488294a2163dafac0d7a",
      "720f0d35f91d4fa29f5e34f8349053c4",
      "7ab49054d40c422cbab64b6b8af027c9",
      "6904bf672c89427d85649001242b6c00",
      "5a3696cd119a40c093be6b73adf39363",
      "d2610ff66e634fd19128a237f1b13259",
      "ff4120474b254e78b8a41a6327bc78a2",
      "0956adda726343a083476d7c84e71d84",
      "b5751b0f9653411193a97db9d0bc2e50",
      "6d1ae4fd77f94b238ca4e01535c37983",
      "72287d7396bd4891891ef883f8ae7a16",
      "94b66f9dd67c4a8caab73b8995fda8fd",
      "e7ca37aa8b1445aca84240d9ea80f470",
      "1b94b81f275247f493b6bf570352db99",
      "7cc61a9b36da49fa8c8acd195044e2da",
      "584ec2d6883845aeb5b615e216e2fa09",
      "6189c65e42254149857969e7096ac0db",
      "83a8269fe35246f0b9b68d3247131ec4",
      "30c783682aca4edb80f01e68a7f85071",
      "01ab3125c7e24a8397a3625c46c78ae8",
      "e840460a337440f4b3e023bf7f7fbfb2",
      "61d7ef361f2542caa9d99a3408878461",
      "9eb044a94a1647c89b7ade95b2aecc91",
      "d04a8acf2fcf49b3b5b3fd9ddf4f7cb6",
      "955d390a41a34a9eaddd0d07e51fcd8a",
      "9010c36feff24829bf5ba2353a0b6198",
      "e40736d1fae04a24baef5be7874a887d",
      "b466a59846a444c09ca631deab5dd636",
      "9df17cc84603415695f12b5b93cced2a",
      "b7c8b5af4743478d84b7441380043afe",
      "ee662757d7d94e5f949c1c4320a45ed7"
     ]
    },
    "executionInfo": {
     "elapsed": 12212,
     "status": "ok",
     "timestamp": 1756368930499,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "oonOfqRivejq",
    "outputId": "5890ace3-1526-4bf5-95b0-5e20b2fb0c54"
   },
   "outputs": [],
   "source": [
    "df = load_dataset(\"mlabonne/FineTome-100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61,
     "referenced_widgets": [
      "4590b864569e47f78d363ba901c586a0",
      "4cda3c95c34a4c7d86c1134d3ff5249f",
      "4e63665614d24018aa6b2b8659cac3de",
      "105c98e0aa4746c09fdc462966227fff",
      "8d7f7ac816314cc9966070776e7ac02c",
      "d9428f3647534c819d005b7ab192d2e4",
      "1e8df0858f594054afc14ce924314088",
      "3f5c060196ad4e2d82c3331f19e4c80f",
      "2321a22d463444fa97dee6c2792cc9b9",
      "a7b8b0ff871541adbc3fea1750cf9f30",
      "51f35635d80d425c9b946c03c011b959"
     ]
    },
    "executionInfo": {
     "elapsed": 8722,
     "status": "ok",
     "timestamp": 1756369120263,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "Cxse6dEsvrMV",
    "outputId": "843da2c4-26c5-48cd-a362-1d1ba791b04e"
   },
   "outputs": [],
   "source": [
    "dataset = standardize_sharegpt(df['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1756369180448,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "5eFnkFBfwEyY",
    "outputId": "aeb89db5-bee9-45cb-fa97-f6c703c340eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'source', 'score'],\n",
       "    num_rows: 100000\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ccaad91856f84f39b620151ff8dc6884",
      "88b47cdb3c4f4c6eb1b3684e30b91b24",
      "781e85f195994f8e8c5c1daa665dc117",
      "c5b0fc69c63840899e821c622b4a2548",
      "066dded54e8f485380b4d3efacfeacc1",
      "e2cd83704452443689d4a535d249cb46",
      "36c03ce16fe1485f983eaef978466f12",
      "ecad733a5b094965bc1b557dbc8bdcb3",
      "86b16e31d06c4ceea50fd6256cd78947",
      "ffe49a9a445348d785c39cc668199d76",
      "35c4c2f0cac6455494c0ed83b962272d"
     ]
    },
    "executionInfo": {
     "elapsed": 20803,
     "status": "ok",
     "timestamp": 1756370233121,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "dWPdCUCYwvAQ",
    "outputId": "07c19ee7-cf07-4d8e-ac09-980d0d84daf1"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda examples: {\n",
    "        \"text\":[\n",
    "            tokenizer.apply_chat_template(convo, tokenize = False)\n",
    "            for convo in examples[\"conversations\"]\n",
    "        ]\n",
    "    },\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "187c61ee44bc4abbbe82d75afe061948",
      "c983d5a0e4454561846e5f401b66bfa2",
      "a3f60e0bd1f44b519acd4880f6056c48",
      "64a5e8efdbe34c9897cc209a08774158",
      "46ad2a4d2c4d4cd19306a1515f8d688d",
      "53973df50add43bdbfc158d5007cd34e",
      "f6174eea78cf467fa4e5015f0c19d328",
      "2ab616e4e652409d8fbd743928342170",
      "89e102122cf641478af40abd28b23305",
      "5ff31fcb871943fc8089fd4899a17716",
      "cc235509010e446d9bcebb73286bd39d"
     ]
    },
    "executionInfo": {
     "elapsed": 181654,
     "status": "ok",
     "timestamp": 1756370559203,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "060d9ZzGzDVx",
    "outputId": "53727008-9af8-46e2-b259-de75d67f1bb6"
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    # dataset_text_field = \"text\", # Commenting this out as formatting_func is required\n",
    "    max_seq_length = 2048,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = 1,\n",
    "        output_dir = \"outputs\",\n",
    "        optim= \"paged_adamw_8bit\"\n",
    "    ),\n",
    "    formatting_func=lambda example: example[\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 302381,
     "status": "ok",
     "timestamp": 1756370891120,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "hBpniF5-z1nB",
    "outputId": "73bf2550-8046-4fcc-f152-f265d6ae3f22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 100,000 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 11,272,192 of 1,247,086,592 (0.90% trained)\n",
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myashgamerz0007\u001b[0m (\u001b[33myashgamerz0007-sgu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250828_084458-ycnbu69b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashgamerz0007-sgu/huggingface/runs/ycnbu69b' target=\"_blank\">expert-lake-1</a></strong> to <a href='https://wandb.ai/yashgamerz0007-sgu/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashgamerz0007-sgu/huggingface' target=\"_blank\">https://wandb.ai/yashgamerz0007-sgu/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashgamerz0007-sgu/huggingface/runs/ycnbu69b' target=\"_blank\">https://wandb.ai/yashgamerz0007-sgu/huggingface/runs/ycnbu69b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 02:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.523900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.574400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.310600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.936200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.408900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.323700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.956100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.097800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.841500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.837400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.023200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=1.1570710917313893, metrics={'train_runtime': 297.1206, 'train_samples_per_second': 1.616, 'train_steps_per_second': 0.202, 'total_flos': 1902923896037376.0, 'train_loss': 1.1570710917313893})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEqwYNyW2E9P"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"finetune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26518,
     "status": "ok",
     "timestamp": 1756371104596,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "Qa-VBVz72lRH",
    "outputId": "eae10146-8cfd-4014-ba08-b757d17b0201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.9: Fast Llama patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "interface_model, interface_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"./finetune\",\n",
    "    max_seq_length=2048,\n",
    "    load_in_4bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12425,
     "status": "ok",
     "timestamp": 1756371936451,
     "user": {
      "displayName": "Reiki",
      "userId": "10847197557030288006"
     },
     "user_tz": -330
    },
    "id": "cTkyK9Gc3e3W",
    "outputId": "288b8308-d8c7-4887-97e4-524d3ff7e739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 28 Aug 2025\n",
      "\n",
      "user\n",
      "\n",
      "what are the key principles of investmentsassistant\n",
      "\n",
      "Key principles of investments include:\n",
      "\n",
      "1. Diversification: Spreading investments across different asset classes, sectors, and geographic regions to minimize risk and maximize potential returns.\n",
      "2. Asset allocation: Allocating investments to different asset classes based on risk tolerance, investment horizon, and financial goals.\n",
      "3. Risk management: Identifying and mitigating potential risks, such as market volatility, liquidity, and credit risk.\n",
      "4. Downtime management: Managing potential losses during market downturns or periods of low interest rates.\n",
      "5. Regular portfolio rebalancing: Periodically reviewing and adjusting the investment portfolio to maintain its target asset allocation and risk level.\n",
      "6. Tax efficiency: Minimizing taxes on investment returns by using tax-efficient investment strategies and strategies to reduce tax liabilities.\n",
      "7. ESG (Environmental, Social, and Governance) investing: Considering the environmental, social, and governance impacts of investments to promote sustainable investing.\n",
      "8. Long-term focus: Prioritizing long-term investment goals over short-term gains or market fluctuations.\n",
      "9. Diversification across sectors: Investing in a diversified portfolio across different sectors to minimize risk and maximize potential returns.\n",
      "10. Risk assessment: Regularly assessing and managing potential risks to ensure the portfolio remains aligned with investment goals and risk tolerance.\n",
      "\n",
      "By following these key principles of investments, investors can increase their chances of achieving their financial goals while managing risk and minimizing potential losses.\n"
     ]
    }
   ],
   "source": [
    "test_prompts = {\n",
    "    \"what are the key principles of investments\"\n",
    "}\n",
    "for prompt in test_prompts:\n",
    "  formatted_prompt = interface_tokenizer.apply_chat_template([{\n",
    "      \"role\": \"user\",\n",
    "      \"content\" : prompt\n",
    "      }], tokenize=False)\n",
    "\n",
    "  model_input = interface_tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "  generated_ids = interface_model.generate(\n",
    "      **model_input,\n",
    "      # max_temprature = 0.7, # Removed unsupported argument\n",
    "      # do_samples=True, # Removed unsupported argument\n",
    "      pad_token_id =interface_tokenizer.pad_token_id\n",
    "  )\n",
    "  response = interface_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "  print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQkmkbP36Z9X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
